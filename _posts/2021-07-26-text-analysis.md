---
layout: post
title: Text Analysis
excerpt: "Trials in CTA"
modified: 9/7/2021, 9:00:24
tags: [intro, scholarship, digital, digital humanities]
comments: false
category: blog
---

I unsurprisingly faced some significant technical difficulties with computational text analysis this past week. I was able to successfully use Voyant and Lexos, but Tableau was not compatible with my computer no matter which way I tried to download it. So, I might be a bit biased in my conclusion that human text analysis is better for my purposes, at least. 

## The Tools  
Voyant and Lexos were relatively easy to use with a tutorial, I'm just not sure that they are the best tools for me to use based on what I want to research. I did, however, like that they had lots of options on what you could do, Voyant especially; the program yields some really cool visuals, or at least I thought so as someone with an interest in language. I could definitely see myself using programs like this in the future in my study of English and my interest in social media analytics, beecause keywords, words that could bee connected, word trends, etc. are all really useful things to know in that field - just getting that data would be a bit harder! 

## Human Text Analysis  
I have a strong background in human text analysis, so that is definitely an area of comfort for me. I'm used to the research and write approach, or comparing different texts together based on observation. I think, to a certain extent, my brain now knows what to look for when I read a text for analysis. That being said, I can make mistakes; I might define a word incorrectly, or misquote something, or make a factually incorrect statement. CTA does not make "mistakes" in the sense that it produces the correct result based on the information it is provided with. Ideally, I think they are best used in conjunction with one another to get the most complete result possible. 

